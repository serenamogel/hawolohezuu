<!doctype html><html class=no-js lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Where We're Going, We Don't Need Nodes - VoxVibe</title><script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content="The typical view of a cluster or supercomputer that uses a GPU, an FPGA or a Xeon Phi type device is that each node in the system requires one host or CPU to communicate through the PCIe root complex to 1-4 coprocessors. In some circumstances, the CPU/host model adds complexity, when all you really need"><meta name=robots content="index,follow,noarchive"><meta property="og:title" content="Where We're Going, We Don't Need Nodes"><meta property="og:description" content="The typical view of a cluster or supercomputer that uses a GPU, an FPGA or a Xeon Phi type device is that each node in the system requires one host or CPU to communicate through the PCIe root complex to 1-4 coprocessors. In some circumstances, the CPU/host model adds complexity, when all you really need"><meta property="og:type" content="article"><meta property="og:url" content="/hostindependent-pcie-compute-where-were-going-we-dont-need-nodes.html"><meta property="article:section" content="post"><meta property="article:published_time" content="2024-08-07T00:00:00+00:00"><meta property="article:modified_time" content="2024-08-07T00:00:00+00:00"><meta itemprop=name content="Where We're Going, We Don't Need Nodes"><meta itemprop=description content="The typical view of a cluster or supercomputer that uses a GPU, an FPGA or a Xeon Phi type device is that each node in the system requires one host or CPU to communicate through the PCIe root complex to 1-4 coprocessors. In some circumstances, the CPU/host model adds complexity, when all you really need"><meta itemprop=datePublished content="2024-08-07T00:00:00+00:00"><meta itemprop=dateModified content="2024-08-07T00:00:00+00:00"><meta itemprop=wordCount content="1140"><meta itemprop=keywords content><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=https://assets.cdnweb.info/hugo/mainroad/css/style.css><link rel="shortcut icon" href=./favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=./index.html title=VoxVibe rel=home><div class="logo__item logo__text"><div class=logo__title>VoxVibe</div></div></a></div><div class=divider></div></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>Where We're Going, We Don't Need Nodes</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2024-08-07T00:00:00Z>August 07, 2024</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=./categories/blog/ rel=category>blog</a></span></div></div></header><div class="content post__content clearfix"><p>The typical view of a cluster or supercomputer that uses a GPU, an FPGA or a Xeon Phi type device is that each node in the system requires one host or CPU to communicate through the PCIe root complex to 1-4 coprocessors. In some circumstances, the CPU/host model adds complexity, when all you really need is more coprocessors. This is where host-independent compute comes in.</p><p>The CPU handles the networking transfer and when combined with the south&nbsp;bridge, manages the IO and other features. Some orientations allow the coprocessors to talk directly with each other, and the CPU part allows large datasets to be held in local host DRAM. However for some compute workloads, all you need is more coprocessor cards. Storage and memory might be decentralized, and adding in hosts creates cost and complexity - a host that seamlessly has access to 20 coprocessors is easier to handle than 20 hosts with one each. This is the goal of EXTOLL as part of the DEEP (Dynamical Exascale&nbsp;Entry Platform) Project.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9851/5%20-%20Comm%20Paths_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>At SuperComputing 15, one of the academic&nbsp;posters on display from <a href=#>Sarah Neuwirth</a> and her team from the University of Heidelberg was around developing the hardware and software stacks to allow for host-independent PCIe coprocessors through a custom fabric. This is theory would allow for compute nodes in a cluster to be split specifically into CPU and PCIe compute nodes, depending on the need of the simulation, but also allows for fail over or multiple user access. All of this is developed through their EXTOLL network interface chip, which has subsequently been spun out into a commercial entity.</p><p>A side note - In academia, it is common enough that the best ideas, if they're not locked down by funding terms and conditions, are spun out into commercial enterprises. With enough university or venture capital in exchange for a percentage of ownership, an academic team can hire external experts to make their ideas a commercial product. These ideas either work and fail, or sometimes the intellectual property is sold up the chain to a tech industry giant.</p><p>The concept of EXTOLL is to act as a mini-host to initialize the coprocessor but also handles the routing and memory address translation such that it is transparent to all parties involved.&nbsp; On a coprocessor with EXTOLL equipped, it can be connected into a fabric of other compute, storage and host nodes and yet be accessible to all. Multiple hosts can connect into the fabric, and coprocessors in the fabric can communicate directly to each other without the need to move out to a host. This is all controlled via MPI command extensions for which the interface is optimised.</p><p><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9851/1%20-%20Top%20Level%20Diagram_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>The top level representation of the EXTOLL gives seven external ports supporting cluster architectures up to a 3D Torus plus one extra. The internal switch manages which network port is in use, derived from the translation layer provided by the IP blocks: VELO is the Virtualized Engine for Low Overhead that deals with MPI and in particular small messages, RMA is the Remote Memory Access unit that implements put/get with one-or-zero-copy operations and zero CPU interaction, and the SMFU which is the Shared Memory Function Unit for exporting segments of local memory to remote nodes. This all communicates to the PCIe coprocessor via the host interface which supports both PCIe 3.0 or HyperTransport 3.0.</p><p><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9851/2%20-%20System%20and%20User%20View_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>From topology point of view, EXTOLL is not to act as a replacement for a regular network fabric and adds in a separate fabric layer. In the diagram above, the exploded view gives compute and host nodes (CN) offering standard fabric options, booster interface nodes (BI) that have both the standard fabric and EXTOLL fabric, then booster nodes (BN) which are just the PCIe coprocessor and an EXTOLL NIC. With this there can be a 1 to many or a many to many representation depending on what is needed, or in most cases the BI and BN can be combined into a single unit. From the end users perspective, this should all be seamless.</p><p><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9851/3%20-%20Hardware%20Components_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>I discussed this&nbsp;and was told that several users could allocate themselves a certain number of coprocessors or the admin can set the limits depending on login or other workloads queued.</p><p>On the software side, EXTOLL sits between the coprocessor driver as a virtual PCI&nbsp;layer. This communicates to the hardware through the EXTOLL driver, telling the hardware to perform the required methods of address translation or MPI messages etc. The driver provides the tools to do the necessary translation of PCI commands across its own API.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9851/4%20-%20Software%20Stack_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>The goal of something like EXTOLL is to be part of the PCIe coprocessor itself, similar to how Omni-Path will be on Knights Landing, either as a custom IC on the package or internal to the die. That way the EXTOLL connected devices can be developed into devices in a different physical format to the standard PCIe coprocessor cards, perhaps with integrated power and cooling to make design more efficient.&nbsp; The first generation of this was built on an FPGA and used as an add-in to a power and data only PCIe interface. The second generation is similar, but this time has moved out into a 65nm TSMC based ASIC, reducing power and increasing performance.&nbsp;The latest version is the <a href=#>Tourmalet card</a>, using upgraded IP blocks and featuring 100 GB/s per direction and&nbsp;1.75 TB/s switching capacity.</p><p><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/9851/Hardware-Bring-up-2013_575px.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a><br>Early hardware in the <a href=#>DEEP Project</a>, to which EXTOLL is a key part</p><p>Current tests with the 2nd generation, the Galibier, and a dual node design gave LAMMPS (a biochemistry library) speed up of 57%.</p><p>The concept of host-less PCIe coprocessors is one of the next steps towards exascale&nbsp;computing, and EXTOLL are now straddling the line between commercial products and presenting their research as part of academic endeavours, even though there is the goal of external investment, similar to a startup. I am told they already have interest and proof of concept deployment with two partners, but this sort of technology needs to be integrated into the coprocessor itself - having something the size of a motherboard&nbsp;with several coprocessors talking via EXTOLL without external cables should be part of the endgame here, as long as power and cooling can be controlled. The other factor is ease of integration with software. If it fits easily into current MPI based codes and libraries, on C++ and FORTRAN, and it can be supported as new hardware is developed with new use cases, then it is a positive step. Arguably EXTOLL thus needs to be brought into on of the large tech firms, most likely as an IP purchase, or others will develop something similar depending on patents. Arguably the best person into that position will be Intel with its Omni-Path, but consider that FPGA vendors have close ties to Infiniband, so&nbsp;there could be potential there.</p><p>Relevant Paper:&nbsp;<a href=#>Scalable Communication Architecture for&nbsp;Network-Attached Accelerators</a></p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZIZ5gZBon6irpJ67pbHPnqWdnZ6perGvyJ5knKedpcK1sYywn56qlWLEpr7EZp6ooZ6cerixjJ2mp6xdo7KmsIynpp2dow%3D%3D</p></div></article></main><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=./best-margarine.html rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>Best Margarine: The Best Tasting Margarine at the Grocery Store</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=./scott-sibella-net-worth-275879.html rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>Scott Sibella Net Worth 2024</p></a></div></nav></div><aside class=sidebar><div class="widget-recent widget"><h4 class=widget__title>Recent Posts</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=./246919-diddy-poses-with-his-6-kids-trendy-festi-html.html>Diddy Poses With His 6 Kids in Trendy Festive Outfits See the Heart-Melting Family Photos</a></li><li class=widget__item><a class=widget__link href=./apple-ios-5-review.html>iCloud: iOS 5 Integration and Store Updates</a></li><li class=widget__item><a class=widget__link href=./who-is-iddo-goldberg-wife-ashley-madekwe-everything-to-know-about-the-actor-208248-html.html>Who Is Iddo Goldberg Wife Ashley Madekwe? Everything To Know About The Actor</a></li><li class=widget__item><a class=widget__link href=./who-is-ricky-negron-on-finding-magic-mike-and-where-is-he-from-heres-a-short-bio.html>Who Is Ricky Negron On Finding Magic Mike And Where Is He From? Heres A Short Bio</a></li><li class=widget__item><a class=widget__link href=./matilda-szydagis.html>Inside The Life Of Matilda Szydagis - Bio, Net Worth &amp;amp; Husband</a></li></ul></div></div><div class="widget-categories widget"><h4 class=widget__title>Categories</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=./categories/blog/>blog</a></li></ul></div></div></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2024 VoxVibe.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=https://assets.cdnweb.info/hugo/mainroad/js/menu.js></script>
<script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>